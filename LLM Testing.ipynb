{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96595492-5693-44fd-8352-be30fc6a1368",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LLM Testing\n",
    "\n",
    "In this code, we load 10 patient stems and 26 anticoagulation profiles, creating 260 scenarios. We define a way to systematically query the GPT API with these scenarios, and then for a given `PROMPT_ID` in `prompts` we test all scenarios. We do this in batches of `batch_size` and we repeat our tests for a number of `duplication_folds`. Finally, we concatenate our results, take the mean of each scenario, and save.\n",
    "\n",
    "This code should run with relatively little setup. Be sure to have initialized an OpenAI account (see https://platform.openai.com/docs/api-reference/introduction). Once you have done that, point `openai.api_key_path` to wherever you have saved your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd575ad8-f687-43a5-9a9b-059bbcaff494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.__version__='1.5.3', np.__version__='1.24.2', matplotlib.__version__='3.7.1'\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests.exceptions\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(f'{pd.__version__=}, {np.__version__=}, {matplotlib.__version__=}')\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9c6973-302c-413b-ade0-e3faeb7784c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d9d24-4706-42e8-8f27-edda810f1092",
   "metadata": {},
   "source": [
    "Edit the code below to wherever your API key lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856e5588-ae11-4bb2-bc41-10e0e5af53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key_path = '../api_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7710f8-04ae-4a24-9352-8c522887c4c0",
   "metadata": {},
   "source": [
    "Models:\n",
    "\n",
    "- gpt-3.5-turbo : most powerful (at time of experiments) model, costs \\$0.0020 per 1k tokens. Max 4,096 tokens per request. Current version is gpt-3.5-turbo-0301. Trained up to Sept 2021.\n",
    "- ada : fastest model, costs \\$0.0004 per 1k tokens (1/5 of 3.5). Max 2,049 tokens per request. Trained up to Oct 2019.\n",
    "- babbage : slightly slower than ada, but more nuanced. Costs \\$0.0005 per 1k tokens. Max 2,049 tokens per request. Trained up to Oct 2019.\n",
    "- curie : again slower, costs \\$0.0020 per 1k tokens (same price as 3.5). Max 2,049 tokens per request. Trained up to Oct 2019.\n",
    "- davinci : strongest 3.0 model, comparable to 3.5 turbo. Costs \\$0.0200 per 1k tokens (10x cost of 3.5). Max 2,049 tokens per request. Trained up to Oct 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b19f6098-653e-4dbe-ae1e-5e60b23e91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo-0301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8303db3-1bbe-46e9-85ff-c21733afdee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenarios loaded. There are currently 260 possible scenarios.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Patient AA: A 50-year-old woman with a history of diabetes, atrial fibrillation, and ulcerative colitis presents for an open colectomy.  The surgical team is requesting epidural analgesia for postoperative pain control.  Her medications include metformin, acetaminophen, and  5000 Units subcutaneous heparin TID. The last dose of heparin was 3 hours before the planned procedure.',\n",
       " 'Patient AB: A 50-year-old woman with a history of diabetes, atrial fibrillation, and ulcerative colitis presents for an open colectomy.  The surgical team is requesting epidural analgesia for postoperative pain control.  Her medications include metformin, acetaminophen, and  5000 Units subcutaneous heparin TID. The last dose of heparin was 8 hours before the planned procedure.',\n",
       " 'Patient AC: A 50-year-old woman with a history of diabetes, atrial fibrillation, and ulcerative colitis presents for an open colectomy.  The surgical team is requesting epidural analgesia for postoperative pain control.  Her medications include metformin, acetaminophen, and  10,000 Units subcutaneous heparin TID. The last dose of heparin was 3 hours before the planned procedure.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('patient_stems.txt') as f:\n",
    "    pt_stems = [line.strip() for line in f]\n",
    "    \n",
    "with open('med_stems.txt') as f:\n",
    "    meds = [' ' + line.strip() for line in f]\n",
    "    \n",
    "with open('prompt_stems.txt') as f:\n",
    "    prompts = [' ' + line.strip() for line in f]\n",
    "    \n",
    "print(f'Scenarios loaded. There are currently {len(pt_stems)*len(meds)} possible scenarios.')\n",
    "\n",
    "scenarios = []\n",
    "for i in range(len(pt_stems)):\n",
    "    for j in range(len(meds)):\n",
    "        patient = chr(ord('A') + i) + chr(ord('A') + j)\n",
    "        scenario = f'Patient {patient}: {pt_stems[i]} {meds[j]}'\n",
    "        scenarios.append(scenario)\n",
    "\n",
    "\n",
    "scenarios[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168b429-4d5a-41b5-9530-da9de6ad6afe",
   "metadata": {},
   "source": [
    "In the box below, choose which prompt to test by setting PROMPT_ID.\n",
    "\n",
    "- 0 = baseline\n",
    "- 1 = Summary by ChatGPT 3.5\n",
    "- 2 = Summary by ChatGPT 4\n",
    "- 3 = Corrected Summary by ChatGPT 4\n",
    "- 4 = Explicit Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006c35d3-8556-412e-9b19-bc45b8c51ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_ID = 0\n",
    "\n",
    "prompt = prompts[PROMPT_ID]\n",
    "\n",
    "save_name = 'out.csv'\n",
    "if PROMPT_ID == 0:\n",
    "    save_name = '0baseline.csv'\n",
    "elif PROMPT_ID == 1:\n",
    "    save_name = '1gpt3.csv'\n",
    "elif PROMPT_ID == 2:\n",
    "    save_name = '2gpt4.csv'\n",
    "elif PROMPT_ID == 3:\n",
    "    save_name = '3gpt4corr.csv'\n",
    "elif PROMPT_ID == 4:\n",
    "    save_name = '4explicit.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5e8a68-e717-47d1-b132-70c1f96ef215",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "duplication_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b790045-a140-4084-aa65-e4e28e4934ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(test_scenarios):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are an assistant to an anesthesiologist planning procedures.'},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "        {'role': 'assistant', \"content\": \"Sure, I can help you with that. Please provide me with the patient scenarios.\",},\n",
    "        #{\n",
    "        #    'role': 'user',\n",
    "        #    'content': PROMPT_HERE\n",
    "        #},\n",
    "    ]\n",
    "    for scenario in test_scenarios:\n",
    "        messages.append(\n",
    "                {\n",
    "            'role': 'user',\n",
    "            'content': scenario\n",
    "        }\n",
    "            )\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db30ae98-d676-4510-a874-ef76216d1d85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 0 Finished fold 0. Total time elapsed: 116.81s\n",
      "Starting fold 1 Finished fold 1. Total time elapsed: 223.63s\n",
      "Starting fold 2 Finished fold 2. Total time elapsed: 335.25s\n",
      "Starting fold 3 Finished fold 3. Total time elapsed: 437.10s\n",
      "Starting fold 4 Finished fold 4. Total time elapsed: 537.90s\n",
      "Starting fold 5 Finished fold 5. Total time elapsed: 655.56s\n",
      "Starting fold 6 Finished fold 6. Total time elapsed: 774.01s\n",
      "Starting fold 7 Finished fold 7. Total time elapsed: 875.69s\n",
      "Starting fold 8 Finished fold 8. Total time elapsed: 993.65s\n",
      "Starting fold 9 Finished fold 9. Total time elapsed: 1101.18s\n",
      "Task completed with 427543 total tokens and a total cost of $0.85. Total time elapsed: 1101.18s (18.35 minutes)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the scenarios\n",
    "random.seed(1234)\n",
    "random.shuffle(scenarios)\n",
    "\n",
    "token_count = 0\n",
    "start_time = time.time()\n",
    "results = []\n",
    "for fold in range(duplication_folds):\n",
    "    \n",
    "    print(f\"Starting fold {fold}\", end=\" \")\n",
    "    random.shuffle(scenarios)\n",
    "    \n",
    "    for i in range(0, len(scenarios), batch_size):\n",
    "        thous_tokens = token_count // 1000\n",
    "        cost = 0.002 * thous_tokens\n",
    "        #print(f'{i=}, {thous_tokens=:.0f}k tokens ${cost:.3f}', end=' ')\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=model,\n",
    "                    messages=get_messages(scenarios[i:i+batch_size]),\n",
    "                    temperature=0,\n",
    "                )\n",
    "                #Check to ensure model wasn't cut off\n",
    "                if response['choices'][0]['finish_reason'] != 'stop':\n",
    "                    raise Exception('Response failed- message incomplete')\n",
    "                \n",
    "                #Check to ensure output data is formatted correctly\n",
    "                if len(response['choices'][0]['message']['content'].split('~~~')) >= 2:\n",
    "                    break\n",
    "                else:\n",
    "                    print('\\nError occurred with response. Likely misformatted:')\n",
    "                    print(f'Failed on set {i=}, {fold=}. This was the response:')\n",
    "                    print(response['choices'][0]['message']['content'])\n",
    "                    print('Continuing. Reattempting this fold. This response was not added to overall data.')\n",
    "            except (\n",
    "                openai.error.APIConnectionError,\n",
    "                requests.exceptions.Timeout,\n",
    "                requests.exceptions.ConnectionError,\n",
    "                openai.error.APIError,\n",
    "                openai.error.ServiceUnavailableError,\n",
    "                TimeoutError\n",
    "            ) as e:\n",
    "                print(f\"\\nConnection error occurred: {str(e)}: Retrying in 30 seconds...\")\n",
    "                time.sleep(30)                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nUnexpected error occurred: {str(e)}. Retrying in 30 seconds...\")\n",
    "                time.sleep(30)\n",
    "                \n",
    "        token_count += response['usage']['total_tokens']\n",
    "        r = response['choices'][0]['message']['content'].split('~~~')[1].strip()\n",
    "        results.append(pd.read_csv(StringIO(r), sep=';'))\n",
    "        #print(f\"completed. Tokens: {response['usage']['total_tokens']}, time elapsed: {time.time()-start_time:.2f}s\")\n",
    "    print(f'Finished fold {fold}. Total time elapsed: {time.time()-start_time:.2f}s')\n",
    "print(f'Task completed with {token_count} total tokens and a total cost of ${cost:.2f}. Total time elapsed: {time.time()-start_time:.2f}s ({(time.time()-start_time)/60:.2f} minutes)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc6a4b-e0f3-4a04-ba76-ebb56eabb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat(results, ignore_index=True)\n",
    "\n",
    "all_results = all_results[all_results['Safe Intervention'].isin([0,1,'0','1'])]\n",
    "\n",
    "all_results = all_results.astype({'Safe Intervention': 'int'})\n",
    "\n",
    "all_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a643f-d5ee-47ee-96dc-7d3a9350d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = all_results.groupby(['Patient ID']).agg({'Safe Intervention': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9da360-ba25-4818-b3c8-ec95e935b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.to_csv('results/' + save_name)\n",
    "agg_df = agg_df.reset_index()\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d03fb-e3f5-4913-9217-e67a14f843b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
